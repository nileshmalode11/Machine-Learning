{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Wg4DfHgvgavaRbk8Qp1cUBpc4E4Rqm9S",
      "authorship_tag": "ABX9TyMkebKEjkMJCZtj/LQObVWf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nileshmalode11/Machine-Learning/blob/main/nodes_for_kedro_pipeline_aus_whether.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIAxnjdEZDFa"
      },
      "outputs": [],
      "source": [
        "#Importing required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data():\n",
        "  '''importing dataset\n",
        "  output=importing dataset and converting intodataframe'''\n",
        "\n",
        "  df = pd.read_csv(\"/content/drive/MyDrive/weatherAUS.csv.zip\")\n",
        "  return df"
      ],
      "metadata": {
        "id": "Ghr9C69daDMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = get_data()"
      ],
      "metadata": {
        "id": "ogjHN0TSaqWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=get_data()"
      ],
      "metadata": {
        "id": "nf3pa2x5a7-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_treatment(df):\n",
        "  \"\"\"Drop date column from dataframe.\n",
        "  Arg=df\n",
        "  output=Dataframe with no date column.\"\"\"\n",
        "  df.drop([\"Date\"],axis=1,inplace=True)\n",
        "  return df\n",
        "data=data_treatment(df)"
      ],
      "metadata": {
        "id": "Pb_XqLa1lzu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def target_nan(df):\n",
        "  \"\"\"Selecting nan records from target variable.\n",
        "\n",
        "  Arg=df\n",
        "\n",
        "  output=Records with all nan values from target variable.\"\"\"\n",
        "  a=[(i,index) for i,index in enumerate(df[\"RainTomorrow\"]) if pd.isna(index)]\n",
        "  t= pd.DataFrame(a).set_index(0)\n",
        "  return t"
      ],
      "metadata": {
        "id": "S-dBl_DokcmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t=target_nan(df)"
      ],
      "metadata": {
        "id": "lImYjejskgmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inference data extraction.\n",
        "def inference(t):\n",
        "  \"\"\"Separating inference data\n",
        "\n",
        "  Arg=t\n",
        "\n",
        "  output=dataframe of inference data.\"\"\"\n",
        "  index_nan=t.index.tolist()\n",
        "  df_inference=df.iloc[index_nan]\n",
        "  return df_inference\n",
        "df_inference=inference(t)"
      ],
      "metadata": {
        "id": "EeJ489_6kle3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get training data for modelling.\n",
        "def training_data(df_inference):\n",
        "  \"\"\"Separating training data from original dataframe\n",
        "\n",
        "  Arg=df_inference\n",
        "\n",
        "  output=New dataframe with training data only.\"\"\"\n",
        "  index_nan=t.index.tolist()\n",
        "  b=[]\n",
        "  for i in range(df.shape[0]):\n",
        "    if i not in index_nan:\n",
        "      b.append(i)\n",
        "  return b"
      ],
      "metadata": {
        "id": "3-5GFNKJkp-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c=training_data(df_inference)"
      ],
      "metadata": {
        "id": "dGFMjfgPktaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_data(b):\n",
        "  \"\"\"Displaying training data\n",
        "\n",
        "  Arg=b\n",
        "\n",
        "  Output=Seaparate training_data from original dataframe.\"\"\"\n",
        "  df_training_data=df.iloc[b]\n",
        "  return df_training_data"
      ],
      "metadata": {
        "id": "hulwSGh3kxRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_training_data=get_training_data(b)\n",
        "df_training_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "btGMqyock0O8",
        "outputId": "8654b31e-b293-4b0e-a74b-fd97885b83ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-dd1983463cbc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_training_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_training_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'b' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def treat_missing(df_training_data):\n",
        "  \"\"\"treat missing values with ffill and bfill method\n",
        "\n",
        "  Arg=df_training_data\n",
        "\n",
        "  output=nan values from training data get fill with the ffill and bfill method.\"\"\"\n",
        "  df_treat_training_data=df_training_data.fillna(method=\"ffill\",axis=0).fillna(method=\"bfill\",axis=0)\n",
        "  return df_treat_training_data\n",
        "df_treat_training_data=treat_missing(df_training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "M8wj8OdWk3jR",
        "outputId": "c8350557-5bdc-48b6-b296-a26edd41ee48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-8a9ce9762b2f>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mdf_treat_training_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_training_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ffill\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bfill\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdf_treat_training_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf_treat_training_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtreat_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_training_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df_training_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_data_split(df_treat_training_data):\n",
        "  \"\"\"Training data spliting ie.separating predictors and response variables.\n",
        "\n",
        "  Arg=df_treat_training_data\n",
        "\n",
        "  Output=Target variable get separated from main traing data.\"\"\"\n",
        "  X_training=df_treat_training_data.drop([\"RainTomorrow\"],axis=1)\n",
        "  y_training=df_treat_training_data[\"RainTomorrow\"]\n",
        "  return X_training, y_training\n",
        "X_training, y_training=training_data_split(df_treat_training_data)"
      ],
      "metadata": {
        "id": "mDnth2Hkk8Aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "L_Encoder=preprocessing.LabelEncoder()\n",
        "def lebal_encoder(X_training):\n",
        "  \"\"\"Lebal encoding on the discrite varibales.\n",
        "\n",
        "  Arg=X_training\n",
        "\n",
        "  Output=converting categorical data into numeric variable.\"\"\"\n",
        "  X_training[\"Location\"]=L_Encoder.fit_transform(X_training[\"Location\"])\n",
        "  X_training[\"WindGustDir\"]=L_Encoder.fit_transform(X_training[\"WindGustDir\"])\n",
        "  X_training[\"WindDir9am\"]=L_Encoder.fit_transform(X_training[\"WindDir9am\"])\n",
        "  X_training[\"WindDir3pm\"]=L_Encoder.fit_transform(X_training[\"WindDir3pm\"])\n",
        "  X_training[\"RainToday\"]=L_Encoder.fit_transform(X_training[\"RainToday\"])\n",
        "  return X_training\n",
        "X_training=lebal_encoder(X_training)"
      ],
      "metadata": {
        "id": "xy1Xkp61k_uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scalar=StandardScaler()\n",
        "def df_transform(X_training):\n",
        "  \"\"\"perform process of standardization on X_reaining data to minimizes the skewness from records\n",
        "\n",
        "  Arg=X_training\n",
        "\n",
        "  Output=Gets records with some what normal distribution in the records.\"\"\"\n",
        "  model=scalar.fit(X_training)\n",
        "  X_training1=model.transform(X_training)\n",
        "  return X_training1\n",
        "X_training1=df_transform(X_training)"
      ],
      "metadata": {
        "id": "GmKQqCN1lEj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def modelling(X_training1):\n",
        "  \"\"\"Splitting of the x_traing data into X_train,X_test,y_train,y_test data for predicting the output.\n",
        "\n",
        "  Arg=X_training1\n",
        "\n",
        "  output=Get splitted data in the form of train and test data.\"\"\"\n",
        "  X_train,X_test,y_train,y_test=train_test_split(X_training1,y_training,random_state=0,test_size=0.20)\n",
        "  return X_train,X_test,y_train,y_test\n",
        "X_train,X_test,y_train,y_test=modelling(X_training1)"
      ],
      "metadata": {
        "id": "BsGGyZB4lIWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
        "def logReg(X_train,X_test,y_train,y_test):\n",
        "  \"\"\"applying the logistic regression algo on the data after split.\n",
        "\n",
        "  Arg=X_train,X_test,y_train,y_test\n",
        "\n",
        "  Output=data training and output prediction.\"\"\"\n",
        "  logreg.fit(X_train, y_train)\n",
        "  y_pred_train = logreg.predict(X_train)\n",
        "  y_pred_test = logreg.predict(X_test)\n",
        "  return y_pred_train, y_pred_test\n",
        "y_pred_train,y_pred_test=logReg(X_train,X_test,y_train,y_test)"
      ],
      "metadata": {
        "id": "08BjGIYMlMFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "def r2_score(y_pred_train,y_pred_test):\n",
        "  \"\"\"calculate r2_score\n",
        "\n",
        "  Arg=y_pred_train,y_pred_test\n",
        "\n",
        "  output=get r2 score to evaluate the model performance on train and test data.\"\"\"\n",
        "  r2_score_train=accuracy_score(y_train, y_pred_train)\n",
        "  r2_score_test=accuracy_score(y_test, y_pred_test)\n",
        "  return r2_score_train,r2_score_test\n",
        "r2_score_train=r2_score(y_pred_train,y_pred_test)\n",
        "r2_score_test=r2_score(y_pred_train,y_pred_test)"
      ],
      "metadata": {
        "id": "kL8FRav0lPYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score_train\n",
        "r2_score_test"
      ],
      "metadata": {
        "id": "5KkBX99GlTMV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}